************PANDAS***************************
Pythons version of Excel
Import, Display, Manipulate and export tabular Data

****************SERIES********************
Pandas Series = 1D labeled array, arranged as single column
Constructor: 
    Series(data)

Sample Index/Label/Name:
    Series(data, index=(list, tuple, np.array, series))
        Ex for series index:
            series1 = data1
            series2 = pd.Series(data2, index=series1)
                data1   data2
                data1   data2

Locate value with labeled Index:
    Series.loc[index]
Locate value with Integer Index:
    Series.iloc[0, 1, 2...etc]

Series dictionary data includes index:
    Dictionaries Key = Label:
        Key1    value1
        Key2    value2

Conditions from values:
    Series[Series <= 300]

***************DATAFRAME********************
DataFrame = 2D Table with rows and columns
Constructor:
    DataFrame(data)

    data = {key: [list of values]}
    Each key is a column/feature of data

    OR

    data = [{}, {}] 
    data = np.array([], [], [])
    Each {}/[] is a row of data with a value for EVERY column

Sample Index/Label/Name:
    DataFrame(data, index=(list, tuple, np.array, series))

Locate value with labeled Index:
    DataFrame.loc[index]
Locate value with Integer Index:
    DataFrame.iloc[0, 1, 2...etc]
Dictionaries Key = Label:
    Key1    value1
    Key2    value2

New column = New feature for ALL samples
    DataFrame[Feature] = [# Values == # Samples/Rows]

New Row = New Sample with ALL features 
    new_row = pd.DataFrame([{}])
        # rows to add = # dictionaries {}
    oldDataFrame = pd.concat([df, new_row])
        python list of all dataframes to concatenate

New Row WITH index:
    new_rows = pd.DataFrame([row1, row2, row3], index=[index1, index2, index3])
    note: row1,2,3 = {}, {}, {}
    note: indexes must be in list even if single index
        Ex: new_row = pd.DataFrame([{"key": value}], index=["Label"])

***************DATAFRAME IMPORT FILES*********************
NOTE: df = pd.read_csv("file", header=None)
    This means data has no header row (column names),
    just treat first row as data not column names
THEN: df.columns = [new column names]
    MAKE SURE # NAME = # COLS

Setting the csv column to index:
    df = pd.read_csv("Tog_characters.csv", index_col=0)
    Basically if first column is ID's make that the index for each ROW/Sample

Working with JSON (JavaScript Object Notation):
    df = pd.read_json("file.json")
    Ex: Each {} in json is a row of data (Sample)

Printing dimension:
    print(f"\nShape: {df.shape[0]} rows Ã— {df.shape[1]} columns")

****************SELECTION*******************
Selection by column:
    Single Column:
        print(df[column_name])
    Multiple (list of cols):
        print(df[[column_name, column_name]])

Selection by row:
    Single Row:
        print(df.iloc[index]) 
        NOTE: iloc start index = 0
        print(df.loc[index])
        NOTE: if specific label: index = label
    Single Row w/specific columns:
        print(df.loc[column_name, [list of cols]])
    Multiple use slice (start:end:step) operator:
        print(df.loc[column_start:column_end, [list of cols]])
        NOTE: can also slide cols (not inside list)
        print(df.loc[1:10, 0:10])
        *NOTE: if string cols "name":"rank_title" (for loc)
            unless iloc is used [0:4, 0:3]

*******************FILTERING********************
Keeping Rows that match a condition
Ex: wave_controller = df[df["primary_position"] == 'Wave Controller']
Ex: special_character = df[(df["rank_title"] == 'Irregular') |
                       (df["special_position"].notna())]
    NOTE: notna() and isna() for pandas empty strings
    NOTE: NaN != NaN is always true so != None, "", or 'NaN' dont work
    |           |
    V FIX BELOW V
Ex: df = pd.read_csv("Tog_characters.csv", index_col=0, keep_default_na=False)
    df[df["special_position"] != ""] works now! (for empty strings)
    Switch back: df = df.replace("", pd.NA) 

************AGGREGATE FUNCTIONS******************
Reduce SET of values into SINGLE summary value
    Note: often used with groupby()

WHOLE dataframe:
    Ex: Mean of numeric data columns
        print(df.mean(numeric_only=True))
        NOTE: sum(), min(), max()
    Ex: Count number of VALUES within each columns
        df.count() --> no arguments 

Single Column:
    Ex: Mean of numeric data columns
            print(df[column_name].mean())
            NOTE: sum(), min(), max(), count()

Groupby:
    1) Make a group object
        group = df.groupby("Position")
    2) print(group["Height"].mean())
    NOTE: ALL values in each group now SINGLE value/object

****************DATA CLEANING********************
Drop irrelevant columns:
    df = df.drop(columns=[column_name, column_name])

Handle missing data(rows/samples):
    df = df.dropna(subset=[column_name, column_name])
    df = df.fillna({"column_name": replacement_value})

Fix inconsisten values: 
    df[column_name] = df[column_name].replace({"column_value1": new_value1},
                                              {"column_value2": new_value2})
    
Standardize text:
    df[column_name] = df[column_name].str.lower()

Fix data types:
    df[column_name] = df[column_name].astype(bool)

Remove duplicates:
    df = df.drop_duplicates()